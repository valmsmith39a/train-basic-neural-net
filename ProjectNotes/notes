# torch.nn is a:
  * Fully-connected ReLU network
  * Trained to predict y from x by minimizing squared Euclidean distance
# forward pass:
  * Computes values from inputs to output (at each artificial neuron, for all the neurons in all the layers)
# backward pass:
  * Performs backpropagation 
    + Starts at the end of the network and recursively applies
      the chain rule to compute the gradients (at each artificial neuron)
      all the way to the inputs of the circuit
# pass: A forward and backward pass (forward and backward count as 1 pass)
# iteration: one pass 
# batch size:
   * The number of training samples in one pass (forward/backward)
# epoch: one forward and one backward pass of *all* training samples
# randn: function that returns a tensor with random numbers from a normal distribution (Gaussia distribution) with 
  mean 0 and variance 1 (standard normal distribution)
  * Argument 1: batch_size: the number of training samples in one pass. It is the number of rows in the matrix. Each 
    row can be thought of as a vector of attributes. The length of the vector (the number of attributes) describes the dimensionality of the vector.
  * Argument 2: n_in: the number of attributes and is the number of columns in the matrix. 
